{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 276us/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "    player_id  predicted_era_2024\n",
      "0      425794            5.223461\n",
      "1      425844            5.048904\n",
      "2      448179            5.146493\n",
      "3      450203            4.051329\n",
      "4      453286            3.585796\n",
      "..        ...                 ...\n",
      "69     666200            4.168821\n",
      "70     668678            3.646165\n",
      "71     669203            3.192470\n",
      "72     669456            3.726211\n",
      "73     670950            4.784991\n",
      "\n",
      "[74 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predicting 2024 ERA (basic, Full-tft sl=4)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, Flatten, MultiHeadAttention\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'data/basic.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "data = data.drop(columns=['last_name, first_name'])\n",
    "\n",
    "# Handle missing values (e.g., replace with 0)\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Use data from 2020 to 2023 only\n",
    "data = data[data['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "# Extract common player_id with data from 2020 to 2023\n",
    "player_ids_2020 = set(data[data['year'] == 2020]['player_id'].unique())\n",
    "player_ids_2021 = set(data[data['year'] == 2021]['player_id'].unique())\n",
    "player_ids_2022 = set(data[data['year'] == 2022]['player_id'].unique())\n",
    "player_ids_2023 = set(data[data['year'] == 2023]['player_id'].unique())\n",
    "common_player_ids = player_ids_2020 & player_ids_2021 & player_ids_2022 & player_ids_2023\n",
    "\n",
    "# Extract data corresponding to common player_id\n",
    "common_data = data[data['player_id'].isin(common_player_ids)]\n",
    "common_data = common_data.sort_values(by=['player_id', 'year'])\n",
    "\n",
    "# Select necessary columns (excluding year)\n",
    "features = [col for col in common_data.columns if col not in ['player_id', 'year', 'p_era']]\n",
    "target = 'p_era'\n",
    "\n",
    "# Separate independent and dependent variables\n",
    "X = common_data[features].values\n",
    "y = common_data[target].values\n",
    "\n",
    "# Data scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Convert to time series data format\n",
    "def create_sequences(X, seq_length):\n",
    "    \"\"\"\n",
    "    Convert 2020~2023 data for each player into a single sequence.\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    num_players = len(X) // seq_length  # Calculate number of players\n",
    "    for i in range(num_players):\n",
    "        start_idx = i * seq_length\n",
    "        end_idx = start_idx + seq_length\n",
    "        seq_x = X[start_idx:end_idx]\n",
    "        X_seq.append(seq_x)\n",
    "    return np.array(X_seq)\n",
    "\n",
    "seq_length = 4  # Set sequence length\n",
    "X_seq = create_sequences(X_scaled, seq_length)\n",
    "y_seq = y_scaled[seq_length - 1::seq_length]  # Extract the last value for each player\n",
    "\n",
    "# Set training data\n",
    "X_train, y_train = X_seq, y_seq\n",
    "\n",
    "# Define TFT model\n",
    "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, state_size, dropout_rate):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.dense1 = Dense(state_size, activation=\"relu\")\n",
    "        self.dense2 = Dense(input_dim)\n",
    "        self.gate = Dense(input_dim, activation=\"sigmoid\")\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        gate_output = self.gate(inputs)\n",
    "        gated_output = x * gate_output + inputs\n",
    "        return self.layer_norm(gated_output)\n",
    "\n",
    "class TFTModel(Model):\n",
    "    def __init__(self, seq_length, feature_dim, num_heads, ff_dim, state_size, dropout_rate):\n",
    "        super(TFTModel, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(num_heads=num_heads, key_dim=feature_dim)\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.grn1 = GatedResidualNetwork(feature_dim, state_size, dropout_rate)\n",
    "        self.grn2 = GatedResidualNetwork(feature_dim, state_size, dropout_rate)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(state_size, activation=\"relu\")\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dense2 = Dense(state_size // 4, activation=\"relu\")\n",
    "        self.dense3 = Dense(1, activation=\"linear\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.multi_head_attention(inputs, inputs)\n",
    "        out1 = self.layer_norm1(inputs + attn_output)\n",
    "        out1 = self.grn1(out1)\n",
    "        out2 = self.grn2(out1)\n",
    "        flat_output = self.flatten(out2)\n",
    "        dense_output1 = self.dense1(flat_output)\n",
    "        drop_output1 = self.dropout1(dense_output1)\n",
    "        dense_output2 = self.dense2(drop_output1)\n",
    "        return self.dense3(dense_output2)\n",
    "\n",
    "# Set model with fixed hyperparameters\n",
    "state_size = 80\n",
    "dropout_rate = 0.2\n",
    "minibatch_size = 128\n",
    "learning_rate = 0.01\n",
    "max_gradient_norm = 0.01\n",
    "num_heads = 1\n",
    "\n",
    "# Array to store prediction results\n",
    "predictions = []\n",
    "\n",
    "for iteration in range(5):  # Repeat 5 times\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = TFTModel(seq_length=seq_length, feature_dim=X_train.shape[2], num_heads=num_heads, ff_dim=32, state_size=state_size, dropout_rate=dropout_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=max_gradient_norm)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\", \"mae\"])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=minibatch_size, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Predict 2024 data\n",
    "    X_2024_seq = create_sequences(X_scaled, seq_length)\n",
    "    y_pred_scaled = model.predict(X_2024_seq)\n",
    "    predictions.append(scaler_y.inverse_transform(y_pred_scaled).flatten())  # Restore scale and save\n",
    "\n",
    "# Calculate the average of 5 predictions\n",
    "average_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "# Match with player_id and output results\n",
    "player_ids = common_data['player_id'].unique()\n",
    "df_results = pd.DataFrame({\n",
    "    'player_id': player_ids,\n",
    "    'predicted_era_2024': average_prediction\n",
    "})\n",
    "\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "    player_id  predicted_era_2024\n",
      "0      425794            6.882403\n",
      "1      425844            5.394585\n",
      "2      448179            5.186832\n",
      "3      450203            4.358220\n",
      "4      453286            3.927478\n",
      "..        ...                 ...\n",
      "69     666200            4.312869\n",
      "70     668678            3.677975\n",
      "71     669203            3.637825\n",
      "72     669456            3.955359\n",
      "73     670950            4.200325\n",
      "\n",
      "[74 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predicting 2024 ERA (statcast, Full-tft sl=4)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization, Flatten, MultiHeadAttention\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'data/statcast.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['last_name, first_name'])\n",
    "\n",
    "# Handle missing values (e.g., replace with 0)\n",
    "data = data.fillna(0)\n",
    "\n",
    "if 'pitch_hand' in data:\n",
    "    data = pd.get_dummies(data, columns=['pitch_hand'], drop_first=True)\n",
    "\n",
    "# Use only data from 2020 to 2023\n",
    "data = data[data['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "# Extract common player_id with data from 2020 to 2023\n",
    "player_ids_2020 = set(data[data['year'] == 2020]['player_id'].unique())\n",
    "player_ids_2021 = set(data[data['year'] == 2021]['player_id'].unique())\n",
    "player_ids_2022 = set(data[data['year'] == 2022]['player_id'].unique())\n",
    "player_ids_2023 = set(data[data['year'] == 2023]['player_id'].unique())\n",
    "common_player_ids = player_ids_2020 & player_ids_2021 & player_ids_2022 & player_ids_2023\n",
    "\n",
    "# Extract data corresponding to common player_id\n",
    "common_data = data[data['player_id'].isin(common_player_ids)]\n",
    "common_data = common_data.sort_values(by=['player_id', 'year'])\n",
    "\n",
    "# Select necessary columns (excluding year)\n",
    "features = [col for col in common_data.columns if col not in ['player_id', 'year', 'p_era']]\n",
    "target = 'p_era'\n",
    "\n",
    "# Separate independent and dependent variables\n",
    "X = common_data[features].values\n",
    "y = common_data[target].values\n",
    "\n",
    "# Data scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Convert to time series data\n",
    "def create_sequences(X, seq_length):\n",
    "    \"\"\"\n",
    "    Convert each player's 2020-2023 data into a single sequence.\n",
    "    \"\"\"\n",
    "    X_seq = []\n",
    "    num_players = len(X) // seq_length  # Calculate number of players\n",
    "    for i in range(num_players):\n",
    "        start_idx = i * seq_length\n",
    "        end_idx = start_idx + seq_length\n",
    "        seq_x = X[start_idx:end_idx]\n",
    "        X_seq.append(seq_x)\n",
    "    return np.array(X_seq)\n",
    "\n",
    "seq_length = 4  # Set sequence length\n",
    "X_seq = create_sequences(X_scaled, seq_length)\n",
    "y_seq = y_scaled[seq_length - 1::seq_length]  # Extract the last value for each player\n",
    "\n",
    "# Set training data\n",
    "X_train, y_train = X_seq, y_seq\n",
    "\n",
    "# Define TFT model\n",
    "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, state_size, dropout_rate):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.dense1 = Dense(state_size, activation=\"relu\")\n",
    "        self.dense2 = Dense(input_dim)\n",
    "        self.gate = Dense(input_dim, activation=\"sigmoid\")\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        gate_output = self.gate(inputs)\n",
    "        gated_output = x * gate_output + inputs\n",
    "        return self.layer_norm(gated_output)\n",
    "\n",
    "class TFTModel(Model):\n",
    "    def __init__(self, seq_length, feature_dim, num_heads, ff_dim, state_size, dropout_rate):\n",
    "        super(TFTModel, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(num_heads=num_heads, key_dim=feature_dim)\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.grn1 = GatedResidualNetwork(feature_dim, state_size, dropout_rate)\n",
    "        self.grn2 = GatedResidualNetwork(feature_dim, state_size, dropout_rate)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(state_size, activation=\"relu\")\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dense2 = Dense(state_size // 4, activation=\"relu\")\n",
    "        self.dense3 = Dense(1, activation=\"linear\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.multi_head_attention(inputs, inputs)\n",
    "        out1 = self.layer_norm1(inputs + attn_output)\n",
    "        out1 = self.grn1(out1)\n",
    "        out2 = self.grn2(out1)\n",
    "        flat_output = self.flatten(out2)\n",
    "        dense_output1 = self.dense1(flat_output)\n",
    "        drop_output1 = self.dropout1(dense_output1)\n",
    "        dense_output2 = self.dense2(drop_output1)\n",
    "        return self.dense3(dense_output2)\n",
    "\n",
    "# Set model with fixed hyperparameters\n",
    "state_size = 320\n",
    "dropout_rate = 0.4\n",
    "minibatch_size = 64\n",
    "learning_rate = 0.001\n",
    "max_gradient_norm = 0.01\n",
    "num_heads = 4\n",
    "\n",
    "# Array to store prediction results\n",
    "predictions = []\n",
    "\n",
    "for iteration in range(5):  # Repeat 5 times\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = TFTModel(seq_length=seq_length, feature_dim=X_train.shape[2], num_heads=num_heads, ff_dim=32, state_size=state_size, dropout_rate=dropout_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=max_gradient_norm)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\", \"mae\"])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=minibatch_size, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Predict 2024 data\n",
    "    X_2024_seq = create_sequences(X_scaled, seq_length)\n",
    "    y_pred_scaled = model.predict(X_2024_seq)\n",
    "    predictions.append(scaler_y.inverse_transform(y_pred_scaled).flatten())  # Restore scale and save\n",
    "\n",
    "# Calculate average of 5 predictions\n",
    "average_prediction = np.mean(predictions, axis=0)\n",
    "\n",
    "# Match with player_id and output results\n",
    "player_ids = common_data['player_id'].unique()\n",
    "df_results_mps = pd.DataFrame({\n",
    "    'player_id': player_ids,\n",
    "    'predicted_era_2024': average_prediction\n",
    "})\n",
    "\n",
    "print(df_results_mps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
