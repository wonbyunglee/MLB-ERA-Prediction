{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 3s 4ms/step\n",
      "Iteration 1/5 - RMSE: 0.5660322100595585, MAE: 0.45835034851866635, MAPE: 0.13409564965131432\n",
      "7/7 [==============================] - 3s 4ms/step\n",
      "Iteration 2/5 - RMSE: 0.5937387656735622, MAE: 0.4683815256293844, MAPE: 0.14182818013750392\n",
      "7/7 [==============================] - 3s 4ms/step\n",
      "Iteration 3/5 - RMSE: 0.6368079389842757, MAE: 0.4937485359947462, MAPE: 0.15286983196961404\n",
      "7/7 [==============================] - 4s 4ms/step\n",
      "Iteration 4/5 - RMSE: 0.5835983861493096, MAE: 0.46708793481191, MAPE: 0.1366183805364076\n",
      "7/7 [==============================] - 5s 6ms/step\n",
      "Iteration 5/5 - RMSE: 0.573920067393226, MAE: 0.4590487418428135, MAPE: 0.13869542829673703\n",
      "Average RMSE: 0.5908194736519864\n",
      "Average MAE: 0.4693234173595041\n",
      "Average MAPE: 0.14082149411831538\n"
     ]
    }
   ],
   "source": [
    "# BiLSTM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'data/basic.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['last_name, first_name'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Extract player_ids that exist in 2020, 2021, 2022, and 2023\n",
    "data_2021 = data[data['year'] == 2021]\n",
    "data_2022 = data[data['year'] == 2022]\n",
    "data_2023 = data[data['year'] == 2023]\n",
    "\n",
    "player_ids_2021 = set(data_2021['player_id'].unique())\n",
    "player_ids_2022 = set(data_2022['player_id'].unique())\n",
    "player_ids_2023 = set(data_2023['player_id'].unique())\n",
    "\n",
    "common_player_ids = player_ids_2021 & player_ids_2022 & player_ids_2023\n",
    "\n",
    "# Extract data for common player_ids\n",
    "common_data = data[data['player_id'].isin(common_player_ids)]\n",
    "\n",
    "# Extract data for the years 2020, 2021, and 2022\n",
    "final = common_data[common_data['year'].isin([2021, 2022])]\n",
    "final = final.sort_values(by=['player_id', 'year'])\n",
    "\n",
    "# Select necessary columns (excluding year)\n",
    "features = [col for col in final.columns if col not in ['player_id', 'year', 'p_era']]\n",
    "target = 'p_era'\n",
    "\n",
    "# Split independent and dependent variables\n",
    "X = final[features].values\n",
    "y = final[target].values\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Function to create sequences for time series data\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X)):\n",
    "        seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "        seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "        seq_y = y[i]\n",
    "        X_seq.append(seq_x)\n",
    "        y_seq.append(seq_y)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 2  # Set sequence length\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Set training data\n",
    "X_train, y_train = X_seq, y_seq\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "iterations = 5\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "mape_list = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Initialize the BiLSTM model\n",
    "    model_BiLSTM = Sequential()\n",
    "    model_BiLSTM.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(seq_length, X_train.shape[2])))\n",
    "    model_BiLSTM.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model_BiLSTM.add(Dropout(rate=0.5))\n",
    "    model_BiLSTM.add(Flatten())\n",
    "    model_BiLSTM.add(Dense(512, activation=\"relu\"))\n",
    "    model_BiLSTM.add(Dropout(rate=0.5))\n",
    "    model_BiLSTM.add(Dense(64, activation=\"relu\"))\n",
    "    model_BiLSTM.add(Dense(1, activation='relu'))\n",
    "\n",
    "    # Compile the model\n",
    "    adam = optimizers.Adam(learning_rate=0.001)\n",
    "    model_BiLSTM.compile(loss=\"mse\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiLSTM = model_BiLSTM.fit(X_train, y_train, epochs=500, batch_size=64, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Filter 2023 data\n",
    "    data_23 = common_data[common_data['year'] == 2023]\n",
    "\n",
    "    # Scale 2023 data\n",
    "    X_2023_scaled = scaler_X.transform(data_23[features].values)\n",
    "\n",
    "    # Function to create sequences for prediction\n",
    "    def create_sequences_for_prediction(X, seq_length):\n",
    "        X_seq = []\n",
    "        for i in range(len(X)):\n",
    "            seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "            seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "            X_seq.append(seq_x)\n",
    "        return np.array(X_seq)\n",
    "\n",
    "    X_2023_seq = create_sequences_for_prediction(X_2023_scaled, seq_length)\n",
    "\n",
    "    # Predict 2023 data\n",
    "    y_pred_scaled_BiLSTM = model_BiLSTM.predict(X_2023_seq)\n",
    "\n",
    "    # Inverse scale the predictions\n",
    "    y_pred_BiLSTM = scaler_y.inverse_transform(y_pred_scaled_BiLSTM)\n",
    "\n",
    "    # Actual 2023 p_era values\n",
    "    y_test_actual = data_23[target].values\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse_BiLSTM = np.sqrt(mean_squared_error(y_test_actual, y_pred_BiLSTM))\n",
    "    rmse_list.append(rmse_BiLSTM)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_BiLSTM = mean_absolute_error(y_test_actual, y_pred_BiLSTM)\n",
    "    mae_list.append(mae_BiLSTM)\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape_BiLSTM = mean_absolute_percentage_error(y_test_actual, y_pred_BiLSTM)\n",
    "    mape_list.append(mape_BiLSTM)\n",
    "\n",
    "    print(f'Iteration {i+1}/{iterations} - RMSE: {rmse_BiLSTM}, MAE: {mae_BiLSTM}, MAPE: {mape_BiLSTM}')\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "avg_mae = np.mean(mae_list)\n",
    "avg_mape = np.mean(mape_list)\n",
    "\n",
    "print(f'Average RMSE: {avg_rmse}')\n",
    "print(f'Average MAE: {avg_mae}')\n",
    "print(f'Average MAPE: {avg_mape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 3ms/step\n",
      "Iteration 1/5 - RMSE: 0.5834117286087327, MAE: 0.46010137221663466, MAPE: 0.13493078845143738\n",
      "7/7 [==============================] - 6s 3ms/step\n",
      "Iteration 2/5 - RMSE: 0.5771130485800154, MAE: 0.4578184389952875, MAPE: 0.13010316451267362\n",
      "7/7 [==============================] - 5s 3ms/step\n",
      "Iteration 3/5 - RMSE: 0.5961494592479916, MAE: 0.4696075754810647, MAPE: 0.1407665598439919\n",
      "7/7 [==============================] - 5s 3ms/step\n",
      "Iteration 4/5 - RMSE: 0.5991552883673206, MAE: 0.47398185448946, MAPE: 0.14207667549401384\n",
      "7/7 [==============================] - 5s 3ms/step\n",
      "Iteration 5/5 - RMSE: 0.5793713008451793, MAE: 0.4518655560442791, MAPE: 0.13349208159891235\n",
      "Average RMSE: 0.5870401651298479\n",
      "Average MAE: 0.4626749594453452\n",
      "Average MAPE: 0.1362738539802058\n"
     ]
    }
   ],
   "source": [
    "# CNN-BiLSTM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Reshape\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/basic.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['last_name, first_name'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Extract player_ids that exist in 2021, 2022, and 2023\n",
    "data_2021 = data[data['year'] == 2021]\n",
    "data_2022 = data[data['year'] == 2022]\n",
    "data_2023 = data[data['year'] == 2023]\n",
    "\n",
    "player_ids_2021 = set(data_2021['player_id'].unique())\n",
    "player_ids_2022 = set(data_2022['player_id'].unique())\n",
    "player_ids_2023 = set(data_2023['player_id'].unique())\n",
    "\n",
    "common_player_ids = player_ids_2021 & player_ids_2022 & player_ids_2023\n",
    "\n",
    "# Extract data for common player_ids\n",
    "common_data = data[data['player_id'].isin(common_player_ids)]\n",
    "\n",
    "# Extract data for the years 2021, and 2022\n",
    "final = common_data[common_data['year'].isin([2021, 2022])]\n",
    "final = final.sort_values(by=['player_id', 'year'])\n",
    "\n",
    "# Select necessary columns (excluding year)\n",
    "features = [col for col in final.columns if col not in ['player_id', 'year', 'p_era']]\n",
    "target = 'p_era'\n",
    "\n",
    "# Split independent and dependent variables\n",
    "X = final[features].values\n",
    "y = final[target].values\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Function to create sequences for time series data\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X)):\n",
    "        seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "        seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "        seq_y = y[i]\n",
    "        X_seq.append(seq_x)\n",
    "        y_seq.append(seq_y)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 2  # Set sequence length\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Set training data\n",
    "X_train, y_train = X_seq, y_seq\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "iterations = 5\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "mape_list = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Initialize the CNN-BiLSTM model\n",
    "    model_CNN_BiLSTM = Sequential()\n",
    "    model_CNN_BiLSTM.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(seq_length, X_train.shape[2])))\n",
    "    model_CNN_BiLSTM.add(Flatten())\n",
    "    model_CNN_BiLSTM.add(Dense(64, activation='relu'))\n",
    "    model_CNN_BiLSTM.add(Reshape((1, 64)))\n",
    "    model_CNN_BiLSTM.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model_CNN_BiLSTM.add(Bidirectional(LSTM(64)))\n",
    "    model_CNN_BiLSTM.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    adam = optimizers.Adam(learning_rate=0.001)\n",
    "    model_CNN_BiLSTM.compile(loss=\"mse\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_CNN_BiLSTM = model_CNN_BiLSTM.fit(X_train, y_train, epochs=500, batch_size=64, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Filter 2023 data\n",
    "    data_23 = common_data[common_data['year'] == 2023]\n",
    "\n",
    "    # Scale 2023 data\n",
    "    X_2023_scaled = scaler_X.transform(data_23[features].values)\n",
    "\n",
    "    # Function to create sequences for prediction\n",
    "    def create_sequences_for_prediction(X, seq_length):\n",
    "        X_seq = []\n",
    "        for i in range(len(X)):\n",
    "            seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "            seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "            X_seq.append(seq_x)\n",
    "        return np.array(X_seq)\n",
    "\n",
    "    X_2023_seq = create_sequences_for_prediction(X_2023_scaled, seq_length)\n",
    "\n",
    "    # Predict 2023 data\n",
    "    y_pred_scaled_CNN_BiLSTM = model_CNN_BiLSTM.predict(X_2023_seq)\n",
    "\n",
    "    # Inverse scale the predictions\n",
    "    y_pred_CNN_BiLSTM = scaler_y.inverse_transform(y_pred_scaled_CNN_BiLSTM)\n",
    "\n",
    "    # Actual 2023 p_era values\n",
    "    y_test_actual = data_23[target].values\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse_CNN_BiLSTM = np.sqrt(mean_squared_error(y_test_actual, y_pred_CNN_BiLSTM))\n",
    "    rmse_list.append(rmse_CNN_BiLSTM)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_CNN_BiLSTM = mean_absolute_error(y_test_actual, y_pred_CNN_BiLSTM)\n",
    "    mae_list.append(mae_CNN_BiLSTM)\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape_CNN_BiLSTM = mean_absolute_percentage_error(y_test_actual, y_pred_CNN_BiLSTM)\n",
    "    mape_list.append(mape_CNN_BiLSTM)\n",
    "\n",
    "    print(f'Iteration {i+1}/{iterations} - RMSE: {rmse_CNN_BiLSTM}, MAE: {mae_CNN_BiLSTM}, MAPE: {mape_CNN_BiLSTM}')\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "avg_mae = np.mean(mae_list)\n",
    "avg_mape = np.mean(mape_list)\n",
    "\n",
    "print(f'Average RMSE: {avg_rmse}')\n",
    "print(f'Average MAE: {avg_mae}')\n",
    "print(f'Average MAPE: {avg_mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 4ms/step\n",
      "Iteration 1/5 - RMSE: 0.5640586156898868, MAE: 0.44392712699042425, MAPE: 0.13363803576877095\n",
      "7/7 [==============================] - 3s 3ms/step\n",
      "Iteration 2/5 - RMSE: 0.5535645057634186, MAE: 0.4345002790119336, MAPE: 0.12991219761157682\n",
      "7/7 [==============================] - 4s 3ms/step\n",
      "Iteration 3/5 - RMSE: 0.5709070399299884, MAE: 0.4465085271936683, MAPE: 0.12951569168702265\n",
      "7/7 [==============================] - 4s 3ms/step\n",
      "Iteration 4/5 - RMSE: 0.5608169767521333, MAE: 0.4426853538826468, MAPE: 0.13479911771202588\n",
      "7/7 [==============================] - 2s 3ms/step\n",
      "Iteration 5/5 - RMSE: 0.5397060605888827, MAE: 0.4261696818485351, MAPE: 0.1251104171537953\n",
      "Average RMSE: 0.557810639744862\n",
      "Average MAE: 0.4387581937854416\n",
      "Average MAPE: 0.13059509198663832\n"
     ]
    }
   ],
   "source": [
    "# BiLSTM-ED\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Flatten, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/basic.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['last_name, first_name'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Extract player_ids that exist in 2021, 2022, and 2023\n",
    "data_2021 = data[data['year'] == 2021]\n",
    "data_2022 = data[data['year'] == 2022]\n",
    "data_2023 = data[data['year'] == 2023]\n",
    "\n",
    "player_ids_2021 = set(data_2021['player_id'].unique())\n",
    "player_ids_2022 = set(data_2022['player_id'].unique())\n",
    "player_ids_2023 = set(data_2023['player_id'].unique())\n",
    "\n",
    "common_player_ids = player_ids_2021 & player_ids_2022 & player_ids_2023\n",
    "\n",
    "# Extract data for common player_ids\n",
    "common_data = data[data['player_id'].isin(common_player_ids)]\n",
    "\n",
    "# Extract data for the years 2021, and 2022\n",
    "final = common_data[common_data['year'].isin([2021, 2022])]\n",
    "final = final.sort_values(by=['player_id', 'year'])\n",
    "\n",
    "# Select necessary columns (excluding year)\n",
    "features = [col for col in final.columns if col not in ['player_id', 'year', 'p_era']]\n",
    "target = 'p_era'\n",
    "\n",
    "# Split independent and dependent variables\n",
    "X = final[features].values\n",
    "y = final[target].values\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Function to create sequences for time series data\n",
    "def create_sequences(X, y, seq_length):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X)):\n",
    "        seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "        seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "        seq_y = y[i]\n",
    "        X_seq.append(seq_x)\n",
    "        y_seq.append(seq_y)\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "seq_length = 2  # Set sequence length\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, seq_length)\n",
    "\n",
    "# Set training data\n",
    "X_train, y_train = X_seq, y_seq\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "iterations = 5\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "mape_list = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Initialize the BiLSTM-ED model\n",
    "    model_BiLSTM_ED = Sequential()\n",
    "    model_BiLSTM_ED.add(Bidirectional(LSTM(64, return_sequences=False), input_shape=(seq_length, X_train.shape[2])))\n",
    "    model_BiLSTM_ED.add(RepeatVector(seq_length))\n",
    "    model_BiLSTM_ED.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model_BiLSTM_ED.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "    # Compile the model\n",
    "    adam = optimizers.Adam(learning_rate=0.001)\n",
    "    model_BiLSTM_ED.compile(loss=\"mse\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history_BiLSTM_ED = model_BiLSTM_ED.fit(X_train, y_train, epochs=500, batch_size=64, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "    # Filter 2023 data\n",
    "    data_23 = common_data[common_data['year'] == 2023]\n",
    "\n",
    "    # Scale 2023 data\n",
    "    X_2023_scaled = scaler_X.transform(data_23[features].values)\n",
    "\n",
    "    # Function to create sequences for prediction\n",
    "    def create_sequences_for_prediction(X, seq_length):\n",
    "        X_seq = []\n",
    "        for i in range(len(X)):\n",
    "            seq_x = X[max(0, i - seq_length + 1):i + 1]\n",
    "            seq_x = np.pad(seq_x, ((seq_length - len(seq_x), 0), (0, 0)), 'constant')\n",
    "            X_seq.append(seq_x)\n",
    "        return np.array(X_seq)\n",
    "\n",
    "    X_2023_seq = create_sequences_for_prediction(X_2023_scaled, seq_length)\n",
    "\n",
    "    # Predict 2023 data\n",
    "    y_pred_scaled_BiLSTM_ED = model_BiLSTM_ED.predict(X_2023_seq)\n",
    "\n",
    "    # Inverse scale the predictions\n",
    "    y_pred_BiLSTM_ED = scaler_y.inverse_transform(y_pred_scaled_BiLSTM_ED[:, -1, :])  # Take the last time step\n",
    "\n",
    "    # Actual 2023 p_era values\n",
    "    y_test_actual = data_23[target].values\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse_BiLSTM_ED = np.sqrt(mean_squared_error(y_test_actual, y_pred_BiLSTM_ED))\n",
    "    rmse_list.append(rmse_BiLSTM_ED)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_BiLSTM_ED = mean_absolute_error(y_test_actual, y_pred_BiLSTM_ED)\n",
    "    mae_list.append(mae_BiLSTM_ED)\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape_BiLSTM_ED = mean_absolute_percentage_error(y_test_actual, y_pred_BiLSTM_ED)\n",
    "    mape_list.append(mape_BiLSTM_ED)\n",
    "\n",
    "    print(f'Iteration {i+1}/{iterations} - RMSE: {rmse_BiLSTM_ED}, MAE: {mae_BiLSTM_ED}, MAPE: {mape_BiLSTM_ED}')\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "avg_mae = np.mean(mae_list)\n",
    "avg_mape = np.mean(mape_list)\n",
    "\n",
    "print(f'Average RMSE: {avg_rmse}')\n",
    "print(f'Average MAE: {avg_mae}')\n",
    "print(f'Average MAPE: {avg_mape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
